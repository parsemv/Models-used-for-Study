{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4276d-1c3b-4331-b309-2102f054ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, DepthwiseConv2D, BatchNormalization, ReLU,\n",
    "    GlobalAveragePooling2D, Dense, Add, Reshape, LayerNormalization,\n",
    "    MultiHeadAttention, Flatten\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 14\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "train_dir = \"c:/MyData/train\"\n",
    "val_dir = \"c:/MyData/val\"\n",
    "\n",
    "# Depthwise Separable Conv Block + GAP Skip\n",
    "def dsc_block_with_skip(x_input, filters):\n",
    "    # Main path\n",
    "    x = DepthwiseConv2D(kernel_size=3, padding='same', use_bias=False)(x_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # GAP skip path\n",
    "    gap = GlobalAveragePooling2D()(x_input)\n",
    "    gap = Dense(filters, activation='relu')(gap)\n",
    "    gap = tf.expand_dims(tf.expand_dims(gap, 1), 1)\n",
    "    gap = tf.tile(gap, [1, tf.shape(x)[1], tf.shape(x)[2], 1])\n",
    "\n",
    "    # Residual add\n",
    "    x = Add()([x, gap])\n",
    "    return x\n",
    "\n",
    "# Patch Embedding for ViT\n",
    "def patch_embedding(x, patch_size=8, embed_dim=256):\n",
    "    x = Conv2D(embed_dim, patch_size, strides=patch_size, padding='valid')(x)\n",
    "    x = Reshape((-1, embed_dim))(x)\n",
    "    return x\n",
    "\n",
    "# Vision Transformer block\n",
    "def vit_block(x, num_heads=2):\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(x_norm, x_norm)\n",
    "    x = Add()([x, attn_output])\n",
    "    x_norm2 = LayerNormalization()(x)\n",
    "    mlp_output = Dense(x.shape[-1], activation='relu')(x_norm2)\n",
    "    x = Add()([x, mlp_output])\n",
    "    return x\n",
    "\n",
    "# Full model\n",
    "def build_model():\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x1 = dsc_block_with_skip(inputs, 16)\n",
    "    x2 = dsc_block_with_skip(x1, 32)\n",
    "    x3 = dsc_block_with_skip(x2, 64)\n",
    "    x4 = dsc_block_with_skip(x3, 128)\n",
    "    x5 = dsc_block_with_skip(x4, 256)\n",
    "\n",
    "    # ViT\n",
    "    vit_input = patch_embedding(x5)\n",
    "    vit_out = vit_block(vit_input)\n",
    "\n",
    "    # Classifier head\n",
    "    x = Flatten()(vit_out)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Instantiate and compile model\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Data generators\n",
    "train_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True)\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(train_dir, target_size=(128, 128), batch_size=batch_size, class_mode='categorical')\n",
    "val_data = val_gen.flow_from_directory(val_dir, target_size=(128, 128), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# Training\n",
    "history = model.fit(train_data, epochs=epochs, validation_data=val_data)\n",
    "\n",
    "# Evaluation\n",
    "loss, acc = model.evaluate(val_data)\n",
    "print(f\"\\n Validation Accuracy: {acc*100:.2f}%, Loss: {loss:.4f}\")\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label=\"Train Acc\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"Val Acc\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label=\"Train Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Val Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix + classification report\n",
    "val_labels = val_data.classes\n",
    "class_names = list(val_data.class_indices.keys())\n",
    "predictions = model.predict(val_data)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(val_labels, predicted_classes, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(val_labels, predicted_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(xticks_rotation=90, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
